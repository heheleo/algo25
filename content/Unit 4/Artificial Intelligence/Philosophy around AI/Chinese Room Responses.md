## The Systems Reply
While the person in the room may not understand Chinese, the system as a whole (including the person, the rule book, the symbols, and the room itself) does. The output of the room, when viewed as a single entity, demonstrates understanding.

**Searle's Reply**: By simplifying this list of physical objects: he asks what happens if the man memorises the rules and keeps track of everything in his head? Then the whole system consists of just one object: the man himself. Searle argues that if the man doesn't understand Chinese then the system doesn't understand Chinese either because now "the system" and "the man" both describe exactly the same object.
## The Robot Reply
A fixed computer as confined to the room does not understand Chinese under present considerations. If it had sensory apparatus to connect words with meaning and was suitably programmed, then with with its ability to interact with the physical world, it would be able to understand Chinese (and achieve genuine understanding).

**Searle's Reply**: Suppose that even if some of the inputs came directly from a camera mounted on a robot, and some of the outputs were used to manipulate the arms and legs of the robot. Nevertheless, the person in the room is still just following the rules, and does not know what the symbols mean. Searle writes "he doesn't see what comes into the robot's eyes."
## The Brain Simulator Reply
If the computer's program simulated the actual neural firings of a Chinese speaker's brain, then the computer would understand Chinese, just as a native speaker does

**Searle's Reply**: Searle replies that such a simulation does not reproduce the important features of the brain—its causal and intentional states. Searle is adamant that "human mental phenomena \[are\] dependent on actual physical–chemical properties of actual human brains."
## The Other Minds Reply
One is justified in attributing intelligence to an individual on the basis of purely behavioural criteria.

**Searle's Reply**: Such a mind is, at best, a simulation, and writes: "No one supposes that a computer simulation of a rainstorm will leave us all drenched." Others argue "When we call up the pocket calculator function on a desktop computer, we don't complain that 'it isn't really a calculator', because the physical attributes of the device do not matter." So is the human mind like the pocket calculator, essentially composed of information? Or is the mind like the rainstorm, something other than a computer, and not realisable in full by a computer simulation?
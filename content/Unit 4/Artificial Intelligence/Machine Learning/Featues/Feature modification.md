Features may be transformed (eg $x_{1}\to{2}(x_{1})^2$), such that a linear classifier line can be found.

It may also involve the addition of more features, eg $x_{3}:=x_{1}+3(x_{2})^3$, adding one more dimension to represent a derived statistic.


A common transformation is
$x_{3}:=(x_{1}-c_{1})^2+(x_{2}-c_{2})^2$
Where $x_{1}$ and $x_{2}$ are 2 diff feature/axis, $c_n$ are constants. 
$x_{3}$ represent the square of the distance of any point to the cords $(c_{1},c_{2})$.
Can be used to represent information like resemblance to a certain instance.
![[Pasted image 20250828170452.png]]
[Source](https://www.researchgate.net/figure/Non-linear-classifier-using-Kernel-trick-16_fig4_340618118)
